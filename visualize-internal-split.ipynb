{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9e9cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T06:35:38.530392Z",
     "iopub.status.busy": "2022-05-25T06:35:38.530075Z",
     "iopub.status.idle": "2022-05-25T06:35:38.543620Z",
     "shell.execute_reply": "2022-05-25T06:35:38.542139Z",
     "shell.execute_reply.started": "2022-05-25T06:35:38.530360Z"
    },
    "papermill": {
     "duration": 0.018879,
     "end_time": "2022-05-25T07:01:18.993339",
     "exception": false,
     "start_time": "2022-05-25T07:01:18.974460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "While fitting ALD distributions to the FC layer weights for each class $\\theta_k$, I observed a recursive pattern in the isolated weights. Let $\\theta_k^+$ denote the weights for the positive sub-class [i.e. the possibility that the sample belong to class k] \\& $\\theta_k^-$ denote the weights for the negative class [i.e. the possibility that the sample is outside training set]. I hypothesize that $\\theta_k^+$ and $\\theta_k^-$ can be further sub-divided and fitted with ALD. I hypothesize that the network recursively builds a tree like internal representation for each class.\n",
    "\n",
    "**I have written a more formal summary of my findings in [this document](https://arxiv.org/pdf/2205.11908.pdf).**\n",
    "\n",
    "The results of fitting ALD to FC weights are [here](https://drive.google.com/file/d/1ce90RTQKhYIoxhJrqvhxw6VdjLMEGHkm/view?usp=sharing) and visualization of the most discriminative neurons using Smooth GramCam++ is [here](https://drive.google.com/drive/folders/1aWOlXt20iZJGgaXFMusCTYmJkOyLImLj?usp=sharing).\n",
    "\n",
    "\n",
    "![internal_split](https://raw.githubusercontent.com/sidml/interpret-fc-layer/main/images/internal_split.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f67b33b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-25T07:01:19.030447Z",
     "iopub.status.busy": "2022-05-25T07:01:19.030087Z",
     "iopub.status.idle": "2022-05-25T07:01:58.364588Z",
     "shell.execute_reply": "2022-05-25T07:01:58.363792Z"
    },
    "papermill": {
     "duration": 39.356184,
     "end_time": "2022-05-25T07:01:58.367100",
     "exception": false,
     "start_time": "2022-05-25T07:01:19.010916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m--2022-05-25 07:01:58--  https://raw.githubusercontent.com/rwightman/pytorch-image-models/master/results/results-imagenet.csv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 40205 (39K) [text/plain]\r\n",
      "Saving to: ‘results-imagenet.csv’\r\n",
      "\r\n",
      "results-imagenet.cs 100%[===================>]  39.26K  --.-KB/s    in 0.003s  \r\n",
      "\r\n",
      "2022-05-25 07:01:58 (13.2 MB/s) - ‘results-imagenet.csv’ saved [40205/40205]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm\n",
    "!pip install -q pyvis\n",
    "!pip install -q torchcam\n",
    "!wget https://raw.githubusercontent.com/rwightman/pytorch-image-models/master/results/results-imagenet.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437daf7b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-25T07:01:58.409826Z",
     "iopub.status.busy": "2022-05-25T07:01:58.409225Z",
     "iopub.status.idle": "2022-05-25T07:02:06.767323Z",
     "shell.execute_reply": "2022-05-25T07:02:06.766123Z"
    },
    "papermill": {
     "duration": 8.382446,
     "end_time": "2022-05-25T07:02:06.769927",
     "exception": false,
     "start_time": "2022-05-25T07:01:58.387481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from glob import glob\n",
    "import pdb, json, timm\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchcam.methods import *\n",
    "import torchvision.models as models\n",
    "from torchcam.utils import overlay_mask\n",
    "from pyvis.network import Network\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d139d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:06.812591Z",
     "iopub.status.busy": "2022-05-25T07:02:06.812263Z",
     "iopub.status.idle": "2022-05-25T07:02:06.822819Z",
     "shell.execute_reply": "2022-05-25T07:02:06.822184Z"
    },
    "papermill": {
     "duration": 0.034782,
     "end_time": "2022-05-25T07:02:06.825108",
     "exception": false,
     "start_time": "2022-05-25T07:02:06.790326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting everything to seed 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    print(f'setting everything to seed {seed}')\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# smoothgradcam relies on random noise which may\n",
    "# lead to variable results if seed is not set\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b76cc0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:06.867903Z",
     "iopub.status.busy": "2022-05-25T07:02:06.867627Z",
     "iopub.status.idle": "2022-05-25T07:02:06.881718Z",
     "shell.execute_reply": "2022-05-25T07:02:06.881078Z"
    },
    "papermill": {
     "duration": 0.038287,
     "end_time": "2022-05-25T07:02:06.884070",
     "exception": false,
     "start_time": "2022-05-25T07:02:06.845783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_imagenet_classes(data_dir = \"../input/imagenetval\"):\n",
    "        \n",
    "    # Read the categories\n",
    "    with open(f\"{data_dir}/imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip().lower() for s in f.readlines()]\n",
    "    \n",
    "    # https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n",
    "    cls_map = pd.read_csv(f\"{data_dir}/map_clsloc.txt\", sep=' ', header=None)\n",
    "    cls_map.columns = ['imagenet_label', 'imagenet_clsnum', 'string_label']\n",
    "\n",
    "    with open(f\"{data_dir}/imagenet_class_index.json\") as data_file:    \n",
    "        data = json.load(data_file)              \n",
    "            \n",
    "    cls_stats = pd.DataFrame(data.values(), index=data.keys(),\n",
    "                      columns=['imagenet_label', 'string_label'])\n",
    "    cls_stats.index.name = 'pytorch_clsnum'\n",
    "    cls_stats = cls_stats.reset_index()\n",
    "    cls_stats = cls_stats.set_index('imagenet_label')\n",
    "#     doesn't work for some reason!!!\n",
    "#     cls_stats.loc[cls_map.imagenet_label, \"imagenet_clsnum\"] = cls_map['imagenet_clsnum']\n",
    "    cls_stats.loc[cls_map.imagenet_label, \"imagenet_clsnum\"] = np.arange(1, 1001)\n",
    "    cls_stats['imagenet_clsnum'] = cls_stats['imagenet_clsnum'].astype(int)\n",
    "    \n",
    "    val_sol = pd.read_csv(f\"{data_dir}/LOC_train_solution.csv\")\n",
    "    all_rows = val_sol.PredictionString.apply(lambda x: x.strip().split(' '))\n",
    "\n",
    "    class_counts = val_sol.ImageId.apply(lambda x: x.split('_')[0]).value_counts()\n",
    "    class_counts.name = \"cls_count\"\n",
    "    class_counts.index.name = 'imagenet_label'\n",
    "    cls_stats = cls_stats.merge(class_counts, on='imagenet_label')\n",
    "\n",
    "    cls_stats['pytorch_clsnum'] = cls_stats['pytorch_clsnum'].astype(int)\n",
    "\n",
    "\n",
    "    if cls_stats.index.name!='pytorch_clsnum':\n",
    "        cls_stats = cls_stats.reset_index()\n",
    "        cls_stats = cls_stats.set_index('pytorch_clsnum')\n",
    "\n",
    "    return cls_stats\n",
    "\n",
    "\n",
    "def preprocess_img(img):    \n",
    "    # Preprocess it for your chosen model\n",
    "    input_tensor = normalize(resize(img, (224, 224)) / 255.,\n",
    "                             [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).unsqueeze(0)  \n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58643dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:06.926700Z",
     "iopub.status.busy": "2022-05-25T07:02:06.926279Z",
     "iopub.status.idle": "2022-05-25T07:02:06.930946Z",
     "shell.execute_reply": "2022-05-25T07:02:06.930302Z"
    },
    "papermill": {
     "duration": 0.028229,
     "end_time": "2022-05-25T07:02:06.932822",
     "exception": false,
     "start_time": "2022-05-25T07:02:06.904593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyClass:  # Add Node feature\n",
    "    def __init__(self, name, map2orig_idx, score, pos, parent):\n",
    "        super(MyClass, self).__init__()\n",
    "        self.name = name\n",
    "        self.map2orig_idx = map2orig_idx\n",
    "        self.parent = parent\n",
    "        self.pos = pos\n",
    "        self.score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64b3cc",
   "metadata": {
    "papermill": {
     "duration": 0.020147,
     "end_time": "2022-05-25T07:02:06.973281",
     "exception": false,
     "start_time": "2022-05-25T07:02:06.953134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We recursively split the FC layer weights and apply Smooth GradCam++ using only a subset of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76184ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:07.015644Z",
     "iopub.status.busy": "2022-05-25T07:02:07.015210Z",
     "iopub.status.idle": "2022-05-25T07:02:07.274127Z",
     "shell.execute_reply": "2022-05-25T07:02:07.273185Z"
    },
    "papermill": {
     "duration": 0.283046,
     "end_time": "2022-05-25T07:02:07.276575",
     "exception": false,
     "start_time": "2022-05-25T07:02:06.993529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_image(model, orig_model, pil_im, input_tensor, \n",
    "               cam_extractor, out, map2orig_idx, img_path, cls_num):\n",
    "    # Retrieve the CAM by passing the selected index and the model layer output\n",
    "\n",
    "    model.zero_grad()\n",
    "#     pdb.set_trace()\n",
    "    activation_map = cam_extractor(map2orig_idx, out)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        amap = activation_map[0].unsqueeze(0).unsqueeze(0)\n",
    "        amap = torch.nn.functional.interpolate(amap,  size=(224, 224), mode='bicubic',\n",
    "                                  align_corners=False)\n",
    "        # normalize to 0-1\n",
    "        amap = (amap - amap.min()) / (amap.max() - amap.min())\n",
    "        new_tensor = input_tensor * amap\n",
    "        score = orig_model(new_tensor)\n",
    "        score = torch.nn.functional.softmax(score, -1)[0, cls_num]\n",
    "        \n",
    "    # Resize the CAM and overlay it\n",
    "    result = overlay_mask(pil_im, to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.7)\n",
    "    # Display it\n",
    "    plt.imshow(result); plt.axis('off'); plt.tight_layout()\n",
    "    plt.savefig(img_path); plt.close()\n",
    "    return score\n",
    "        \n",
    "def split_fit(model, orig_model, pil_im, input_tensor, net, out, y_after_split, yorig, node, depth, cam_extractor,\n",
    "              fig_folder,cls_num, spacing=100):\n",
    "    input_tensor.requires_grad = True\n",
    "    y = y_after_split.copy()\n",
    "    if len(y) < 20:\n",
    "        return\n",
    "    else:\n",
    "        depth += 1\n",
    "        mean = np.mean(y)\n",
    "        y = y - mean\n",
    "        pos_idx, neg_idx = np.where(y >= 0)[0], np.where(y < 0)[0]\n",
    "        y_pos, y_neg = y[pos_idx], y[neg_idx]\n",
    "    \n",
    "        pos_node_name, neg_node_name = f'{node.name}_p{depth}', f'{node.name}_m{depth}'\n",
    "        pos_img_path = f\"{fig_folder}/{pos_node_name}.jpg\"\n",
    "        neg_img_path = f\"{fig_folder}/{neg_node_name}.jpg\"\n",
    "\n",
    "        def process_pos_node():\n",
    "            map2orig_idx = {}\n",
    "            for i, idx in enumerate(pos_idx):\n",
    "                map2orig_idx[i] = node.map2orig_idx[idx]\n",
    "            score = save_image(model, orig_model, pil_im, input_tensor, \n",
    "                               cam_extractor, out, list(map2orig_idx.values()), pos_img_path, \n",
    "                              cls_num=cls_num)\n",
    "            pos_node = MyClass(pos_node_name, map2orig_idx=map2orig_idx, score=score,\n",
    "                               parent=node, pos=(node.pos[0]-spacing//2,node.pos[1]+spacing))\n",
    "            net.add_node(pos_node.name, group=depth, x=pos_node.pos[0], y=pos_node.pos[1],\n",
    "                     label=f'p{depth}_score:{score:.3f}', image=pos_img_path,  shape='image')\n",
    "            net.add_edge(node.name, pos_node.name)        \n",
    "            return pos_node\n",
    "\n",
    "        def process_neg_node():\n",
    "            map2orig_idx = {}\n",
    "            for i, idx in enumerate(neg_idx):\n",
    "                map2orig_idx[i] = node.map2orig_idx[idx]\n",
    "            score = save_image(model, orig_model, pil_im, input_tensor, \n",
    "                               cam_extractor, out, list(map2orig_idx.values()), neg_img_path,\n",
    "                              cls_num=cls_num)\n",
    "            neg_node = MyClass(neg_node_name, map2orig_idx=map2orig_idx, score=score,\n",
    "                               parent=node, pos=(node.pos[0]+spacing//2,node.pos[1]+spacing))\n",
    "            net.add_node(neg_node.name, group=depth, x=neg_node.pos[0], y=neg_node.pos[1],\n",
    "                     label=f'm{depth}_score:{score:.3f}', image=neg_img_path,  shape='image')\n",
    "            net.add_edge(node.name, neg_node.name)\n",
    "            return neg_node\n",
    "            \n",
    "        if node.name[-2]=='p':\n",
    "            pos_node =  process_pos_node()\n",
    "            split_fit(model, orig_model, pil_im,input_tensor, net, out, y[pos_idx], yorig, pos_node, depth, cam_extractor, \n",
    "                      fig_folder=fig_folder, spacing=spacing, cls_num=cls_num)\n",
    "        elif node.name[-2]=='m':\n",
    "            neg_node = process_neg_node()    \n",
    "            split_fit(model, orig_model, pil_im, input_tensor, net, out, y[neg_idx], yorig, neg_node, depth, cam_extractor,\n",
    "                      fig_folder=fig_folder, spacing=spacing, cls_num=cls_num)  \n",
    "        else:\n",
    "            pos_node = process_pos_node()\n",
    "            neg_node = process_neg_node()   \n",
    "            split_fit(model, orig_model, pil_im, input_tensor, net, out, y[pos_idx], yorig, pos_node, depth, cam_extractor, \n",
    "                      fig_folder=fig_folder, spacing=spacing, cls_num=cls_num)\n",
    "            split_fit(model, orig_model, pil_im,input_tensor, net, out, y[neg_idx], yorig, neg_node, depth, cam_extractor,\n",
    "                      fig_folder=fig_folder, spacing=spacing, cls_num=cls_num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e532f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:07.319231Z",
     "iopub.status.busy": "2022-05-25T07:02:07.318896Z",
     "iopub.status.idle": "2022-05-25T07:02:07.337640Z",
     "shell.execute_reply": "2022-05-25T07:02:07.336739Z"
    },
    "papermill": {
     "duration": 0.042556,
     "end_time": "2022-05-25T07:02:07.339625",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.297069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_net_overlay(model, orig_model, pil_im, input_tensor, \n",
    "                     cam_extractor, y, model_name, cls_name, cls_num, \n",
    "                     out, orig_score):\n",
    "    depth = 0\n",
    "    pos = (0, 0)\n",
    "    net = Network(height='1080px',\n",
    "                  width='1920px',\n",
    "                  directed=True)\n",
    "    net.heading = f\"{cls_name} Score:{orig_score:.3f}\"\n",
    "    net.add_node('base', value=0, shape='image',\n",
    "                image=f\"./generated/{model_name}/{cls_name}.jpg\")\n",
    "    map2orig_idx = {i:i for i in range(len(y))}\n",
    "    base = MyClass('base', map2orig_idx=map2orig_idx, pos=pos,\n",
    "                  score=orig_score, parent=None)\n",
    "\n",
    "    fig_folder = f\"./generated/{model_name}/{cls_name}/\"\n",
    "    os.makedirs(fig_folder, exist_ok=True)\n",
    "    split_fit(model, orig_model, pil_im=pil_im, input_tensor=input_tensor, \n",
    "              net=net, out=out, y_after_split=y, yorig=y, node=base, depth=depth,\n",
    "              cam_extractor=cam_extractor, fig_folder=fig_folder,\n",
    "              spacing=100, cls_num=cls_num)\n",
    "    net.toggle_physics(False)\n",
    "    net.save_graph(f\"./{model_name}_{cls_name}.html\")\n",
    "\n",
    "    \n",
    "        \n",
    "def viz_model(all_img_fn, cam_extractor, model_name, model, orig_model, fc_w, cls_stats_df, val_sol):\n",
    "    os.makedirs(f\"./generated/{model_name}/\", exist_ok=True)\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "    for i, fn in enumerate(all_img_fn[:200]):\n",
    "        #  extract the class id for the image\n",
    "        extracted_img_id = fn.split('/')[-1][:-5]\n",
    "        actual_cls =  val_sol[val_sol.ImageId==extracted_img_id][\"PredictionString\"].values[0]\n",
    "        actual_cls = actual_cls.split(' ')[0]\n",
    "        sel_row = cls_stats_df.imagenet_label==actual_cls\n",
    "        imagenet_clsnum = cls_stats_df.loc[sel_row,\"imagenet_clsnum\"].values[0]\n",
    "\n",
    "        pytorch_clsnum = cls_stats_df[sel_row].index[0]\n",
    "        \n",
    "        img = read_image(fn)\n",
    "        if img.shape[0]==1: continue\n",
    "        input_tensor = preprocess_img(img)\n",
    "        input_tensor.requires_grad = True\n",
    "        pil_img = to_pil_image(img)\n",
    "        \n",
    "        # Preprocess your data and feed it to the model\n",
    "        model.zero_grad()\n",
    "        out = model(input_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #  get the probability scores for the original model\n",
    "            logit = orig_model(input_tensor)\n",
    "            score = softmax(logit)[:, pytorch_clsnum].squeeze()\n",
    "        \n",
    "        y = fc_w[pytorch_clsnum]\n",
    "        cls_name = cls_stats_df.loc[pytorch_clsnum, \"string_label\"]\n",
    "        cls_name = f\"{i}{cls_name}\"\n",
    "        # save original image for reference\n",
    "        plt.imshow(pil_img); plt.axis('off'); plt.tight_layout()\n",
    "        plt.savefig(f\"./generated/{model_name}/{cls_name}.jpg\"); plt.close()\n",
    "        \n",
    "        save_net_overlay(model, orig_model, pil_img, input_tensor,\n",
    "                         cam_extractor, y, model_name, cls_name,\n",
    "                         cls_num=pytorch_clsnum, out=out,\n",
    "                         orig_score=score)\n",
    "        \n",
    "\n",
    "        print(model_name, fn, cls_name, 'done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442ad0b",
   "metadata": {
    "papermill": {
     "duration": 0.019989,
     "end_time": "2022-05-25T07:02:07.379968",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.359979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We will use models available on timm for our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a3dd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:07.422159Z",
     "iopub.status.busy": "2022-05-25T07:02:07.421848Z",
     "iopub.status.idle": "2022-05-25T07:02:07.440243Z",
     "shell.execute_reply": "2022-05-25T07:02:07.439493Z"
    },
    "papermill": {
     "duration": 0.042181,
     "end_time": "2022-05-25T07:02:07.442533",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.400352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "timm_results = pd.read_csv('results-imagenet.csv')\n",
    "model_names = timm_results.model.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4b563",
   "metadata": {
    "papermill": {
     "duration": 0.021763,
     "end_time": "2022-05-25T07:02:07.484606",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.462843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Extract the FC layer. We also need the original model to generate score predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042b7544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:07.528119Z",
     "iopub.status.busy": "2022-05-25T07:02:07.527563Z",
     "iopub.status.idle": "2022-05-25T07:02:07.536475Z",
     "shell.execute_reply": "2022-05-25T07:02:07.535590Z"
    },
    "papermill": {
     "duration": 0.033192,
     "end_time": "2022-05-25T07:02:07.538902",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.505710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def setup_weights(model_name):\n",
    "    model = timm.create_model(model_name, pretrained=True)\n",
    "    state = model.state_dict()        \n",
    "    # last two layers should be fc\n",
    "    layer_name = list(state.keys())[-2:]\n",
    "    try:\n",
    "        fc_w = state[layer_name[0]].cpu().numpy()\n",
    "        if len(fc_w.shape)!=2:\n",
    "            print(layer_name, fc_w.shape)\n",
    "            print('unable to extract fc layer')\n",
    "            return None, None\n",
    "        if len(layer_name)==2:\n",
    "            fc_b = state[layer_name[1]].cpu().numpy()\n",
    "        else:\n",
    "            fc_b = None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None\n",
    "    orig_model = deepcopy(model)\n",
    "    orig_model.eval()\n",
    "    model.fc = nn.Identity()\n",
    "    model.global_pool = nn.Identity()\n",
    "    model.classifier = nn.Identity()\n",
    "    return fc_w, fc_b, model, orig_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356e279",
   "metadata": {
    "papermill": {
     "duration": 0.02008,
     "end_time": "2022-05-25T07:02:07.579598",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.559518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kaggle kernel time limit will be exceeded if I plot for all the architectures and all the classes.\n",
    "### So I visualize results only for 200 imagenet classes for resnet34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c1f31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:07.622214Z",
     "iopub.status.busy": "2022-05-25T07:02:07.621877Z",
     "iopub.status.idle": "2022-05-25T07:02:11.844004Z",
     "shell.execute_reply": "2022-05-25T07:02:11.843208Z"
    },
    "papermill": {
     "duration": 4.246697,
     "end_time": "2022-05-25T07:02:11.846641",
     "exception": false,
     "start_time": "2022-05-25T07:02:07.599944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_dir = \"/root/.cache/torch/hub/checkpoints/\"\n",
    "data_dir = \"../input/imagenetval\"\n",
    "cls_stats_df = setup_imagenet_classes(data_dir=data_dir)\n",
    "all_fn = glob(\"../input/imagenet/imagenet/train/*.JPEG\")\n",
    "val_sol = pd.read_csv(f\"{data_dir}/LOC_val_solution.csv\")\n",
    "os.makedirs(\"./generated\", exist_ok=True)\n",
    "# comment this if you want to generate results for every image\n",
    "# kaggle kernel time limit will be exceeded so I visualize results only for resnet34.\n",
    "model_names = ['resnet34']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23847935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:02:11.891191Z",
     "iopub.status.busy": "2022-05-25T07:02:11.890401Z",
     "iopub.status.idle": "2022-05-25T07:43:10.369844Z",
     "shell.execute_reply": "2022-05-25T07:43:10.368859Z"
    },
    "papermill": {
     "duration": 2458.504976,
     "end_time": "2022-05-25T07:43:10.373372",
     "exception": false,
     "start_time": "2022-05-25T07:02:11.868396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing: resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021211.JPEG 0tailed_frog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045098.JPEG 1sloth_bear done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00041245.JPEG 2baboon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00020370.JPEG 3nematode done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029391.JPEG 4pool_table done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00026689.JPEG 5papillon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013507.JPEG 6Irish_wolfhound done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039848.JPEG 7chiffonier done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010484.JPEG 8damselfly done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00046886.JPEG 9poncho done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00007995.JPEG 10American_lobster done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00038821.JPEG 11ice_bear done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015192.JPEG 12picket_fence done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00022053.JPEG 13space_bar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043019.JPEG 14sax done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016282.JPEG 15football_helmet done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010112.JPEG 16burrito done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016079.JPEG 17Band_Aid done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015621.JPEG 18ski_mask done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00038855.JPEG 19solar_dish done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043692.JPEG 20loggerhead done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00011083.JPEG 21studio_couch done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021698.JPEG 22typewriter_keyboard done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00033092.JPEG 23brambling done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00017257.JPEG 24electric_fan done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00049925.JPEG 25tractor done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00044635.JPEG 26space_heater done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027567.JPEG 27plow done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034721.JPEG 28shopping_basket done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00033296.JPEG 29neck_brace done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036838.JPEG 30patas done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00024716.JPEG 31pot done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034528.JPEG 32barracouta done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00018448.JPEG 33motor_scooter done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00024920.JPEG 34beacon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00037265.JPEG 35hyena done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045309.JPEG 36viaduct done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00033170.JPEG 37goblet done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027963.JPEG 38cocker_spaniel done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00044901.JPEG 39sloth_bear done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034353.JPEG 40rain_barrel done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043860.JPEG 41tree_frog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021811.JPEG 42plate done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00038026.JPEG 43Chesapeake_Bay_retriever done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013335.JPEG 44bagel done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013176.JPEG 45rule done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00026802.JPEG 46recreational_vehicle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00006572.JPEG 47mosquito_net done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036377.JPEG 48pomegranate done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00040792.JPEG 49hip done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013792.JPEG 50crossword_puzzle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023726.JPEG 51German_short-haired_pointer done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00041418.JPEG 52spotted_salamander done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00041712.JPEG 53balance_beam done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00037377.JPEG 54safe done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010321.JPEG 55file done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00028542.JPEG 56hartebeest done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00019922.JPEG 57whippet done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00044506.JPEG 58stole done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00017828.JPEG 59file done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00008155.JPEG 60jacamar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00018940.JPEG 61sweatshirt done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027244.JPEG 62confectionery done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00014250.JPEG 63African_hunting_dog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034974.JPEG 64kimono done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029888.JPEG 65flat-coated_retriever done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00012228.JPEG 66gown done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023237.JPEG 67gyromitra done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00008576.JPEG 68fountain_pen done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039210.JPEG 69stretcher done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029759.JPEG 70bee done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00037396.JPEG 71Bouvier_des_Flandres done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00041368.JPEG 72fire_screen done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010918.JPEG 73barbell done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00009806.JPEG 74armadillo done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021657.JPEG 75grille done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00020762.JPEG 76beagle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00042226.JPEG 77African_grey done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00024807.JPEG 78submarine done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015224.JPEG 79Gila_monster done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023638.JPEG 80quilt done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00025072.JPEG 81African_elephant done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00048488.JPEG 82German_short-haired_pointer done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00030316.JPEG 83mink done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039473.JPEG 84jaguar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015010.JPEG 85gibbon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032723.JPEG 86barometer done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00014098.JPEG 87pencil_box done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036789.JPEG 88beaker done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013361.JPEG 89Scottish_deerhound done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010922.JPEG 90Polaroid_camera done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00049994.JPEG 91tusker done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032524.JPEG 92giant_schnauzer done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00047869.JPEG 93oboe done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045120.JPEG 94European_fire_salamander done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043898.JPEG 95Persian_cat done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027325.JPEG 96oil_filter done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021057.JPEG 97espresso_maker done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039531.JPEG 98coucal done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034686.JPEG 99tiger done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005859.JPEG 100beer_glass done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021789.JPEG 101perfume done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00049628.JPEG 102amphibian done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029727.JPEG 104bullfrog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010639.JPEG 105fiddler_crab done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00022229.JPEG 106binoculars done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00042462.JPEG 107miniature_poodle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00012113.JPEG 108sea_cucumber done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021814.JPEG 109tow_truck done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00030088.JPEG 110Norwegian_elkhound done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00020993.JPEG 111wreck done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039479.JPEG 112African_chameleon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00033067.JPEG 113Doberman done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010238.JPEG 114Maltese_dog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010464.JPEG 115coral_fungus done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021956.JPEG 116magpie done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005938.JPEG 117hand_blower done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029059.JPEG 118hyena done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016378.JPEG 119barbershop done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032856.JPEG 120pirate done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00040866.JPEG 121rain_barrel done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013007.JPEG 122Old_English_sheepdog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045766.JPEG 123goblet done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00048127.JPEG 124scoreboard done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00013936.JPEG 125daisy done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00019711.JPEG 126church done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010128.JPEG 127chickadee done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00007105.JPEG 128cliff_dwelling done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021132.JPEG 129gown done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00007335.JPEG 130ashcan done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00029420.JPEG 131obelisk done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005370.JPEG 132binder done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036676.JPEG 133bell_pepper done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00040094.JPEG 134green_snake done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00042505.JPEG 135cocktail_shaker done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00022124.JPEG 136mink done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016258.JPEG 137triceratops done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00035194.JPEG 138face_powder done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016297.JPEG 139bassinet done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027278.JPEG 140pool_table done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00021217.JPEG 141shower_curtain done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005198.JPEG 142Pembroke done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045798.JPEG 143school_bus done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039293.JPEG 144necklace done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00016069.JPEG 145waffle_iron done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00048153.JPEG 146stinkhorn done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00034141.JPEG 147measuring_cup done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00037358.JPEG 148koala done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00030342.JPEG 149bullfrog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00038844.JPEG 150swab done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00014790.JPEG 151banded_gecko done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036150.JPEG 152Chihuahua done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00019004.JPEG 153vault done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015793.JPEG 154organ done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00020532.JPEG 155miniskirt done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00019350.JPEG 156space_bar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00026836.JPEG 157banana done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00028187.JPEG 158ruddy_turnstone done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00009144.JPEG 159Old_English_sheepdog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036773.JPEG 160wolf_spider done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010116.JPEG 161European_fire_salamander done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00027330.JPEG 162night_snake done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010362.JPEG 163tricycle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00042754.JPEG 164recreational_vehicle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043622.JPEG 165face_powder done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032239.JPEG 166Irish_terrier done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023420.JPEG 167hog done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00036499.JPEG 168carbonara done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00009916.JPEG 169pomegranate done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00014669.JPEG 170horizontal_bar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00020480.JPEG 171pencil_box done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00006918.JPEG 172geyser done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043241.JPEG 173ruffed_grouse done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00018192.JPEG 174spoonbill done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00040544.JPEG 175pier done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00039777.JPEG 176brown_bear done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00006295.JPEG 177altar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023976.JPEG 178gazelle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00028696.JPEG 179holster done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00024317.JPEG 180pickup done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015315.JPEG 181plunger done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00043705.JPEG 182tiger_beetle done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005810.JPEG 183brass done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032936.JPEG 184butternut_squash done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00047997.JPEG 185face_powder done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00032281.JPEG 186street_sign done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00023695.JPEG 188European_gallinule done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00014544.JPEG 189wooden_spoon done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00046703.JPEG 190chimpanzee done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00005328.JPEG 191ruffed_grouse done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00008657.JPEG 192quill done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00047406.JPEG 193platypus done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00046076.JPEG 194apiary done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00010833.JPEG 195altar done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00045139.JPEG 196leopard done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00007642.JPEG 197vase done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00030085.JPEG 198web_site done\n",
      "resnet34 ../input/imagenet/imagenet/train/ILSVRC2012_val_00015175.JPEG 199hand-held_computer done\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(\"\\nprocessing:\", model_name)\n",
    "    try:\n",
    "        fc_w, fc_b, model, orig_model = setup_weights(model_name)\n",
    "        cam_extractor = SmoothGradCAMpp(model)\n",
    "        cam_extractor._precheck = lambda *args: None\n",
    "        viz_model(all_fn, cam_extractor, model_name, model, orig_model, fc_w, cls_stats_df, val_sol)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        for f in glob(f\"{weight_dir}/*.pth\"):\n",
    "            os.remove(f)   \n",
    "        continue\n",
    "    \n",
    "    for f in glob(f\"{weight_dir}/*.pth\"):\n",
    "        os.remove(f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2386915",
   "metadata": {
    "papermill": {
     "duration": 0.09253,
     "end_time": "2022-05-25T07:43:10.558345",
     "exception": false,
     "start_time": "2022-05-25T07:43:10.465815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Zip and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c359aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T07:43:10.745718Z",
     "iopub.status.busy": "2022-05-25T07:43:10.745157Z",
     "iopub.status.idle": "2022-05-25T07:43:15.169297Z",
     "shell.execute_reply": "2022-05-25T07:43:15.168066Z"
    },
    "papermill": {
     "duration": 4.520784,
     "end_time": "2022-05-25T07:43:15.172077",
     "exception": false,
     "start_time": "2022-05-25T07:43:10.651293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -rq generated.zip ./\n",
    "!rm -rf ./generated/\n",
    "!rm -rf *.html\n",
    "!rm *.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2529.091354,
   "end_time": "2022-05-25T07:43:17.992378",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-25T07:01:08.901024",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
