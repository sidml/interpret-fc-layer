{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88431eae",
   "metadata": {
    "papermill": {
     "duration": 0.015762,
     "end_time": "2022-05-21T09:17:58.051695",
     "exception": false,
     "start_time": "2022-05-21T09:17:58.035933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The main idea is to download pre-trained Imagenet model weights from the timm repository and fit Assymetric Laplace Distribution to the final fully connected layer weights. \n",
    "\n",
    "Please refer to my post https://sidml.github.io/An-interpretation-of-the-final-fully-connected-layer/ for more details about the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8aaa6f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-21T09:17:58.083436Z",
     "iopub.status.busy": "2022-05-21T09:17:58.082659Z",
     "iopub.status.idle": "2022-05-21T09:18:10.352239Z",
     "shell.execute_reply": "2022-05-21T09:18:10.351283Z"
    },
    "papermill": {
     "duration": 12.288186,
     "end_time": "2022-05-21T09:18:10.354868",
     "exception": false,
     "start_time": "2022-05-21T09:17:58.066682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727475df",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:10.389008Z",
     "iopub.status.busy": "2022-05-21T09:18:10.388337Z",
     "iopub.status.idle": "2022-05-21T09:18:11.350813Z",
     "shell.execute_reply": "2022-05-21T09:18:11.350070Z"
    },
    "papermill": {
     "duration": 0.982349,
     "end_time": "2022-05-21T09:18:11.353114",
     "exception": false,
     "start_time": "2022-05-21T09:18:10.370765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-21 09:18:11--  https://raw.githubusercontent.com/rwightman/pytorch-image-models/master/results/results-imagenet.csv\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 40205 (39K) [text/plain]\r\n",
      "Saving to: ‘results-imagenet.csv’\r\n",
      "\r\n",
      "results-imagenet.cs 100%[===================>]  39.26K  --.-KB/s    in 0.004s  \r\n",
      "\r\n",
      "2022-05-21 09:18:11 (9.08 MB/s) - ‘results-imagenet.csv’ saved [40205/40205]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/rwightman/pytorch-image-models/master/results/results-imagenet.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3634e1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:11.388410Z",
     "iopub.status.busy": "2022-05-21T09:18:11.387823Z",
     "iopub.status.idle": "2022-05-21T09:18:19.187573Z",
     "shell.execute_reply": "2022-05-21T09:18:19.186677Z"
    },
    "papermill": {
     "duration": 7.820369,
     "end_time": "2022-05-21T09:18:19.189989",
     "exception": false,
     "start_time": "2022-05-21T09:18:11.369620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import pdb, json, timm, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bf649",
   "metadata": {
    "papermill": {
     "duration": 0.016899,
     "end_time": "2022-05-21T09:18:19.223182",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.206283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Imagenet class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7d92b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:19.257383Z",
     "iopub.status.busy": "2022-05-21T09:18:19.257136Z",
     "iopub.status.idle": "2022-05-21T09:18:19.269166Z",
     "shell.execute_reply": "2022-05-21T09:18:19.268391Z"
    },
    "papermill": {
     "duration": 0.031851,
     "end_time": "2022-05-21T09:18:19.271155",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.239304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_imagenet_classes(data_dir = \"../input/imagenetval\"):\n",
    "        \n",
    "    # Read the categories\n",
    "    with open(f\"{data_dir}/imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip().lower() for s in f.readlines()]\n",
    "    \n",
    "    # https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n",
    "    cls_map = pd.read_csv(f\"{data_dir}/map_clsloc.txt\", sep=' ', header=None)\n",
    "    cls_map.columns = ['imagenet_label', 'imagenet_clsnum', 'string_label']\n",
    "\n",
    "    with open(f\"{data_dir}/imagenet_class_index.json\") as data_file:    \n",
    "        data = json.load(data_file)              \n",
    "            \n",
    "    cls_stats = pd.DataFrame(data.values(), index=data.keys(),\n",
    "                      columns=['imagenet_label', 'string_label'])\n",
    "    cls_stats.index.name = 'pytorch_clsnum'\n",
    "    cls_stats = cls_stats.reset_index()\n",
    "    cls_stats = cls_stats.set_index('imagenet_label')\n",
    "\n",
    "    cls_stats.loc[cls_map.imagenet_label, \"imagenet_clsnum\"] = np.arange(1, 1001)\n",
    "    cls_stats['imagenet_clsnum'] = cls_stats['imagenet_clsnum'].astype(int)\n",
    "    \n",
    "    val_sol = pd.read_csv(f\"{data_dir}/LOC_train_solution.csv\")\n",
    "    # val_sol = pd.read_csv(\"LOC_val_solution.csv\")\n",
    "    all_rows = val_sol.PredictionString.apply(lambda x: x.strip().split(' '))\n",
    "\n",
    "    class_counts = val_sol.ImageId.apply(lambda x: x.split('_')[0]).value_counts()\n",
    "    class_counts.name = \"cls_count\"\n",
    "    class_counts.index.name = 'imagenet_label'\n",
    "    cls_stats = cls_stats.merge(class_counts, on='imagenet_label')\n",
    "\n",
    "    cls_stats['pytorch_clsnum'] = cls_stats['pytorch_clsnum'].astype(int)\n",
    "\n",
    "\n",
    "    if cls_stats.index.name!='pytorch_clsnum':\n",
    "        cls_stats = cls_stats.reset_index()\n",
    "        cls_stats = cls_stats.set_index('pytorch_clsnum')\n",
    "\n",
    "    return cls_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fb4b1",
   "metadata": {
    "papermill": {
     "duration": 0.016011,
     "end_time": "2022-05-21T09:18:19.303690",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.287679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract Final fully connected layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcf695d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:19.337966Z",
     "iopub.status.busy": "2022-05-21T09:18:19.337686Z",
     "iopub.status.idle": "2022-05-21T09:18:19.345504Z",
     "shell.execute_reply": "2022-05-21T09:18:19.344722Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2022-05-21T09:18:19.347515",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.320002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def setup_weights(model_name):\n",
    "    model = timm.create_model(model_name, pretrained=True)    \n",
    "    state = model.state_dict()        \n",
    "    # last two layers should be fc\n",
    "    layer_name = list(state.keys())[-2:]\n",
    "    try:\n",
    "        fc_w = state[layer_name[0]].cpu().numpy()\n",
    "        if len(fc_w.shape)!=2:\n",
    "            print(layer_name, fc_w.shape)\n",
    "            print('unable to extract fc layer')\n",
    "            return None, None\n",
    "        if len(layer_name)==2:\n",
    "            fc_b = state[layer_name[1]].cpu().numpy()\n",
    "        else:\n",
    "            fc_b = None\n",
    "    except Exception as e:\n",
    "        print('couldnt process', model_name)\n",
    "        print(e)\n",
    "        return None, None\n",
    "    return fc_w, fc_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd41b1",
   "metadata": {
    "papermill": {
     "duration": 0.016253,
     "end_time": "2022-05-21T09:18:19.380470",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.364217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit Asymmetric Laplace Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e066a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:19.415338Z",
     "iopub.status.busy": "2022-05-21T09:18:19.415062Z",
     "iopub.status.idle": "2022-05-21T09:18:19.438239Z",
     "shell.execute_reply": "2022-05-21T09:18:19.437405Z"
    },
    "papermill": {
     "duration": 0.043317,
     "end_time": "2022-05-21T09:18:19.440303",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.396986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_laplace(y, fig_name=None):\n",
    "    y = np.sort(y)\n",
    "    x = np.arange(len(y))/len(y)\n",
    "    target = np.log(y)\n",
    "    coeff = np.polyfit(x, target, 1)\n",
    "    predict_y = np.poly1d(coeff)(x)\n",
    "    r2 = r2_score(target, predict_y)\n",
    "    if fig_name:\n",
    "        cls_name = fig_name.split('/')[-1]\n",
    "        plt.plot(predict_y); plt.plot(target)    \n",
    "        plt.legend(['Predicted', 'log(Actual Weights)'])\n",
    "        plt.title(f\"Class :{cls_name}, R2: {r2:.3f}\"); plt.tight_layout();\n",
    "        plt.savefig(f\"{fig_name}.jpg\"); plt.clf()\n",
    "    return coeff[0], coeff[1], r2\n",
    "\n",
    "def fit_joint_laplace(fc_w):\n",
    "    pos_weights = fc_w[fc_w > 0]\n",
    "    neg_weights = -fc_w[fc_w < 0]\n",
    "\n",
    "    slope_pos, int_pos, r2_pos = fit_laplace(pos_weights)\n",
    "    slope_neg, int_neg, r2_neg = fit_laplace(neg_weights)\n",
    "    \n",
    "    # estimate dataset mean assuming joint distribution of iid asymmetric laplace distribution\n",
    "    k_est_pos = np.sqrt(np.exp(int_pos)/(slope_pos-np.exp(int_pos)))\n",
    "    laplace_lam_est_pos = slope_pos * k_est_pos\n",
    "    mean_pos = (1-k_est_pos**2)/(laplace_lam_est_pos*k_est_pos)\n",
    "\n",
    "\n",
    "    k_est_neg = np.sqrt(np.exp(int_neg)/(slope_neg-np.exp(int_neg)))\n",
    "    laplace_lam_est_neg = slope_neg * k_est_neg\n",
    "    mean_neg = (1-k_est_neg**2)/(laplace_lam_est_neg*k_est_neg)\n",
    "\n",
    "    print(f\"joint fit: mean_pos {mean_pos:.2f}, r2_pos {r2_pos:.2f}\")\n",
    "    print(f\"joint fit: mean_neg {mean_neg:.2f}, r2_neg {r2_neg:.2f}\")\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "def fit_exp(cls_stats_df, name, fc_w):\n",
    "    \n",
    "    # reset previous values if they exist and write new values\n",
    "    cls_stats_df.loc[:, ['slope_pos', 'int_pos', 'r2_pos',\\\n",
    "                      'slope_neg', 'int_neg', 'r2_neg']] = None\n",
    "    \n",
    "    os.makedirs(f\"./{name}/pos\", exist_ok=True)\n",
    "    os.makedirs(f\"./{name}/neg\", exist_ok=True)\n",
    "\n",
    "    plt.figure()\n",
    "    for pytorch_clsnum in range(fc_w.shape[0]):\n",
    "        y = fc_w[pytorch_clsnum]\n",
    "        y_pos, y_neg = y[y>=0], -1*y[y<0]\n",
    "        fig_name = f\"./{name}/pos/{cls_stats_df.loc[pytorch_clsnum, 'string_label']}\"\n",
    "        cls_stats_df.loc[pytorch_clsnum, ['slope_pos', 'int_pos', 'r2_pos']] = fit_laplace(y_pos, fig_name)\n",
    "#         fig_name = f\"./{name}/neg/{cls_stats_df.loc[pytorch_clsnum, 'string_label']}\"\n",
    "        cls_stats_df.loc[pytorch_clsnum, ['slope_neg', 'int_neg', 'r2_neg']] = fit_laplace(y_neg, fig_name=None)\n",
    "    plt.close()\n",
    "    \n",
    "                         \n",
    "    all_coeff_pos = cls_stats_df.loc[:, ['slope_pos', 'int_pos']].astype(float).values\n",
    "    all_coeff_neg = cls_stats_df.loc[:, ['slope_neg', 'int_neg']].astype(float).values\n",
    "                         \n",
    "    # estimate mean for each class which is asymmetric laplace distribution\n",
    "    # take mean of all estimated laplace means to obtain overall mean of the dataset\n",
    "    k_est_pos = np.sqrt(np.exp(all_coeff_pos[:, 1])/(all_coeff_pos[:, 0]-np.exp(all_coeff_pos[:, 1])))\n",
    "    laplace_lam_est_pos = all_coeff_pos[:, 0] * k_est_pos\n",
    "    mean_pos = (1-k_est_pos**2)/(laplace_lam_est_pos*k_est_pos)\n",
    "\n",
    "\n",
    "    k_est_neg = np.sqrt(np.exp(all_coeff_neg[:, 1])/(all_coeff_neg[:, 0]-np.exp(all_coeff_neg[:, 1])))\n",
    "    laplace_lam_est_neg = all_coeff_neg[:, 0] * k_est_neg\n",
    "    mean_neg = (1-k_est_neg**2)/(laplace_lam_est_neg*k_est_neg)\n",
    "\n",
    "    marginal_mean_pos, marginal_mean_neg = mean_pos.mean(), mean_neg.mean()\n",
    "    print(f\"marginal_mean_pos:{marginal_mean_pos:.2f}, marginal_mean_neg:{marginal_mean_neg:.2f}\")\n",
    "\n",
    "    # estimate joint laplace\n",
    "    fit_joint_laplace(fc_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    coeff = np.polyfit(all_coeff_pos[:, 0], all_coeff_pos[:, 1], 1)\n",
    "    plt.scatter(all_coeff_pos[:, 0], all_coeff_pos[:, 1])\n",
    "    plt.title(f\"slope:{coeff[0]:.2f}, intercept:{coeff[1]:.2f}\")\n",
    "    plt.savefig(f\"./{name}/pos_coeff_scatter.jpg\")\n",
    "    plt.close()\n",
    "                         \n",
    "    return cls_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2c1c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:19.474433Z",
     "iopub.status.busy": "2022-05-21T09:18:19.474140Z",
     "iopub.status.idle": "2022-05-21T09:18:19.492539Z",
     "shell.execute_reply": "2022-05-21T09:18:19.491871Z"
    },
    "papermill": {
     "duration": 0.037665,
     "end_time": "2022-05-21T09:18:19.494505",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.456840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "timm_results = pd.read_csv('results-imagenet.csv')\n",
    "model_names = timm_results.model.values\n",
    "weight_dir = \"/root/.cache/torch/hub/checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3b85b",
   "metadata": {
    "papermill": {
     "duration": 0.015895,
     "end_time": "2022-05-21T09:18:19.527089",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.511194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kaggle kernels have a disk usage limit, so we can't process all the available models on timm. We will randomly select 75 models for our analysis. Please feel free to run & share the results for all the models if you have sufficient compute.\n",
    "Most of the time is taken while generating the plots. We are saving ALD plots for all the 1000 imagenet classes for every model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102b25f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T09:18:19.561822Z",
     "iopub.status.busy": "2022-05-21T09:18:19.561297Z",
     "iopub.status.idle": "2022-05-21T11:57:16.918980Z",
     "shell.execute_reply": "2022-05-21T11:57:16.917987Z"
    },
    "papermill": {
     "duration": 9537.379277,
     "end_time": "2022-05-21T11:57:16.922892",
     "exception": false,
     "start_time": "2022-05-21T09:18:19.543615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing: gluon_resnet101_v1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet101_v1s-60fe0cc1.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnet101_v1s-60fe0cc1.pth\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "processing: dm_nfnet_f3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-dnf-weights/dm_nfnet_f3-d74ab3aa.pth\" to /root/.cache/torch/hub/checkpoints/dm_nfnet_f3-d74ab3aa.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:522.61, marginal_mean_neg:392.78\n",
      "joint fit: mean_pos 519.62, r2_pos 0.87\n",
      "joint fit: mean_neg 393.91, r2_neg 0.81\n",
      "\n",
      "processing: gluon_resnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnext101_32x4d-b253c8c4.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnext101_32x4d-b253c8c4.pth\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "processing: resnet26t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnet26t_256_ra2-6f6fa748.pth\" to /root/.cache/torch/hub/checkpoints/resnet26t_256_ra2-6f6fa748.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:243.92, marginal_mean_neg:180.13\n",
      "joint fit: mean_pos 243.43, r2_pos 0.87\n",
      "joint fit: mean_neg 180.37, r2_neg 0.82\n",
      "\n",
      "processing: rexnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_100-1b4dddf4.pth\" to /root/.cache/torch/hub/checkpoints/rexnetv1_100-1b4dddf4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:164.87, marginal_mean_neg:144.85\n",
      "joint fit: mean_pos 164.00, r2_pos 0.84\n",
      "joint fit: mean_neg 145.87, r2_neg 0.81\n",
      "\n",
      "processing: efficientnet_el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/DeGirum/pruned-models/releases/download/efficientnet_v1.0/efficientnet_el.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_el.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:232.81, marginal_mean_neg:196.72\n",
      "joint fit: mean_pos 231.75, r2_pos 0.85\n",
      "joint fit: mean_neg 197.89, r2_neg 0.82\n",
      "\n",
      "processing: tf_efficientnet_b3_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b3_ap-aad25bdd.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b3_ap-aad25bdd.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:167.89, marginal_mean_neg:152.55\n",
      "joint fit: mean_pos 167.19, r2_pos 0.82\n",
      "joint fit: mean_neg 153.29, r2_neg 0.80\n",
      "\n",
      "processing: gluon_senet154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_senet154-70a1a3c0.pth\" to /root/.cache/torch/hub/checkpoints/gluon_senet154-70a1a3c0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:880.54, marginal_mean_neg:508.44\n",
      "joint fit: mean_pos 842.25, r2_pos 0.88\n",
      "joint fit: mean_neg 519.94, r2_neg 0.81\n",
      "\n",
      "processing: fbnetc_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/fbnetc_100-c345b898.pth\" to /root/.cache/torch/hub/checkpoints/fbnetc_100-c345b898.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:225.42, marginal_mean_neg:191.09\n",
      "joint fit: mean_pos 224.55, r2_pos 0.84\n",
      "joint fit: mean_neg 192.55, r2_neg 0.82\n",
      "\n",
      "processing: ese_vovnet19b_dw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth\" to /root/.cache/torch/hub/checkpoints/ese_vovnet19b_dw-a8741004.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:205.57, marginal_mean_neg:153.11\n",
      "joint fit: mean_pos 204.49, r2_pos 0.87\n",
      "joint fit: mean_neg 153.61, r2_neg 0.81\n",
      "\n",
      "processing: gluon_resnet50_v1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1b-0ebe02e2.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnet50_v1b-0ebe02e2.pth\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "processing: dpn92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn92_extra-b040e4a9b.pth\" to /root/.cache/torch/hub/checkpoints/dpn92_extra-b040e4a9b.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classifier.weight', 'classifier.bias'] (1000, 2688, 1, 1)\n",
      "unable to extract fc layer\n",
      "unable to extract weights\n",
      "\n",
      "processing: vit_small_patch32_224\n",
      "marginal_mean_pos:370.34, marginal_mean_neg:375.24\n",
      "joint fit: mean_pos 371.35, r2_pos 0.83\n",
      "joint fit: mean_neg 376.69, r2_neg 0.83\n",
      "\n",
      "processing: tf_efficientnet_b8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b8_ra-572d5dd9.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b8_ra-572d5dd9.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:213.05, marginal_mean_neg:206.44\n",
      "joint fit: mean_pos 212.80, r2_pos 0.79\n",
      "joint fit: mean_neg 206.95, r2_neg 0.78\n",
      "\n",
      "processing: resnet32ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnet32ts_256-aacf5250.pth\" to /root/.cache/torch/hub/checkpoints/resnet32ts_256-aacf5250.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:189.86, marginal_mean_neg:150.13\n",
      "joint fit: mean_pos 189.64, r2_pos 0.87\n",
      "joint fit: mean_neg 150.60, r2_neg 0.82\n",
      "\n",
      "processing: resnet33ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnet33ts_256-e91b09a4.pth\" to /root/.cache/torch/hub/checkpoints/resnet33ts_256-e91b09a4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:155.69, marginal_mean_neg:126.92\n",
      "joint fit: mean_pos 155.55, r2_pos 0.86\n",
      "joint fit: mean_neg 127.52, r2_neg 0.82\n",
      "\n",
      "processing: gluon_resnet34_v1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet34_v1b-c6d82d59.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnet34_v1b-c6d82d59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:318.15, marginal_mean_neg:194.65\n",
      "joint fit: mean_pos 316.14, r2_pos 0.89\n",
      "joint fit: mean_neg 194.93, r2_neg 0.80\n",
      "\n",
      "processing: ig_resnext101_32x16d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\" to /root/.cache/torch/hub/checkpoints/ig_resnext101_32x16-c6f796b0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:319.86, marginal_mean_neg:313.28\n",
      "joint fit: mean_pos 319.82, r2_pos 0.76\n",
      "joint fit: mean_neg 313.23, r2_neg 0.75\n",
      "\n",
      "processing: beit_base_patch16_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://unilm.blob.core.windows.net/beit/beit_base_patch16_224_pt22k_ft22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/beit_base_patch16_224_pt22k_ft22kto1k.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid load key, '='.\n",
      "\n",
      "processing: levit_384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/LeViT/LeViT-384-9bdaf2e2.pth\" to /root/.cache/torch/hub/checkpoints/LeViT-384-9bdaf2e2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:73.17, marginal_mean_neg:73.12\n",
      "joint fit: mean_pos 73.18, r2_pos 0.81\n",
      "joint fit: mean_neg 73.12, r2_neg 0.81\n",
      "\n",
      "processing: efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:73.80, marginal_mean_neg:60.56\n",
      "joint fit: mean_pos 73.72, r2_pos 0.85\n",
      "joint fit: mean_neg 60.77, r2_neg 0.81\n",
      "\n",
      "processing: tf_efficientnet_lite1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite1-bde8b488.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_lite1-bde8b488.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:190.99, marginal_mean_neg:163.46\n",
      "joint fit: mean_pos 190.57, r2_pos 0.84\n",
      "joint fit: mean_neg 164.14, r2_neg 0.81\n",
      "\n",
      "processing: swin_tiny_patch4_window7_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\" to /root/.cache/torch/hub/checkpoints/swin_tiny_patch4_window7_224.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:194.80, marginal_mean_neg:194.35\n",
      "joint fit: mean_pos 194.99, r2_pos 0.81\n",
      "joint fit: mean_neg 194.62, r2_neg 0.82\n",
      "\n",
      "processing: crossvit_tiny_240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_tiny_224.pth\" to /root/.cache/torch/hub/checkpoints/crossvit_tiny_224.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:143.86, marginal_mean_neg:145.34\n",
      "joint fit: mean_pos 153.85, r2_pos 0.85\n",
      "joint fit: mean_neg 153.82, r2_neg 0.85\n",
      "\n",
      "processing: ecaresnet50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45402/outputs/ECAResNet50D_833caf58.pth\" to /root/.cache/torch/hub/checkpoints/ECAResNet50D_833caf58.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:1410.23, marginal_mean_neg:1031.97\n",
      "joint fit: mean_pos 1408.94, r2_pos 0.88\n",
      "joint fit: mean_neg 1041.34, r2_neg 0.86\n",
      "\n",
      "processing: rexnet_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rexnet/rexnetv1_200-8c0b7f2d.pth\" to /root/.cache/torch/hub/checkpoints/rexnetv1_200-8c0b7f2d.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:272.47, marginal_mean_neg:214.88\n",
      "joint fit: mean_pos 270.92, r2_pos 0.86\n",
      "joint fit: mean_neg 216.43, r2_neg 0.82\n",
      "\n",
      "processing: regnetx_320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnetx_320-8ea38b93.pth\" to /root/.cache/torch/hub/checkpoints/regnetx_320-8ea38b93.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:534.14, marginal_mean_neg:329.62\n",
      "joint fit: mean_pos 528.10, r2_pos 0.89\n",
      "joint fit: mean_neg 332.69, r2_neg 0.81\n",
      "\n",
      "processing: crossvit_15_dagger_408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/IBM/CrossViT/releases/download/weights-0.1/crossvit_15_dagger_384.pth\" to /root/.cache/torch/hub/checkpoints/crossvit_15_dagger_384.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:127.10, marginal_mean_neg:125.34\n",
      "joint fit: mean_pos 131.63, r2_pos 0.84\n",
      "joint fit: mean_neg 131.49, r2_neg 0.84\n",
      "\n",
      "processing: resnext26ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/resnext26ts_256_ra2-8bbd9106.pth\" to /root/.cache/torch/hub/checkpoints/resnext26ts_256_ra2-8bbd9106.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:200.97, marginal_mean_neg:153.95\n",
      "joint fit: mean_pos 200.72, r2_pos 0.87\n",
      "joint fit: mean_neg 154.26, r2_neg 0.82\n",
      "\n",
      "processing: tf_mixnet_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mixnet_m-0f4d8805.pth\" to /root/.cache/torch/hub/checkpoints/tf_mixnet_m-0f4d8805.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:212.40, marginal_mean_neg:173.89\n",
      "joint fit: mean_pos 210.50, r2_pos 0.84\n",
      "joint fit: mean_neg 175.41, r2_neg 0.80\n",
      "\n",
      "processing: tf_efficientnet_b7_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ns-1dbc32de.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:120.26, marginal_mean_neg:126.52\n",
      "joint fit: mean_pos 120.05, r2_pos 0.70\n",
      "joint fit: mean_neg 126.90, r2_neg 0.72\n",
      "\n",
      "processing: levit_128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/LeViT/LeViT-128-b88c2750.pth\" to /root/.cache/torch/hub/checkpoints/LeViT-128-b88c2750.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:64.13, marginal_mean_neg:63.97\n",
      "joint fit: mean_pos 64.09, r2_pos 0.81\n",
      "joint fit: mean_neg 63.97, r2_neg 0.81\n",
      "\n",
      "processing: tv_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:594.61, marginal_mean_neg:366.87\n",
      "joint fit: mean_pos 590.94, r2_pos 0.89\n",
      "joint fit: mean_neg 367.54, r2_neg 0.81\n",
      "\n",
      "processing: dla60_res2net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-res2net/res2net_dla60_4s-d88db7f9.pth\" to /root/.cache/torch/hub/checkpoints/res2net_dla60_4s-d88db7f9.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc.weight', 'fc.bias'] (1000, 1024, 1, 1)\n",
      "unable to extract fc layer\n",
      "unable to extract weights\n",
      "\n",
      "processing: vit_tiny_patch16_384\n",
      "marginal_mean_pos:309.71, marginal_mean_neg:311.31\n",
      "joint fit: mean_pos 309.49, r2_pos 0.83\n",
      "joint fit: mean_neg 312.03, r2_neg 0.83\n",
      "\n",
      "processing: nfnet_l0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/nfnet_l0_ra2-45c6688d.pth\" to /root/.cache/torch/hub/checkpoints/nfnet_l0_ra2-45c6688d.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:229.24, marginal_mean_neg:178.50\n",
      "joint fit: mean_pos 228.01, r2_pos 0.86\n",
      "joint fit: mean_neg 179.47, r2_neg 0.80\n",
      "\n",
      "processing: tf_efficientnetv2_m_in21ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_m_21ft1k-bf41664a.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnetv2_m_21ft1k-bf41664a.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:490.70, marginal_mean_neg:374.87\n",
      "joint fit: mean_pos 492.91, r2_pos 0.86\n",
      "joint fit: mean_neg 376.84, r2_neg 0.82\n",
      "\n",
      "processing: gcresnext26ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/gcresnext26ts_256-e414378b.pth\" to /root/.cache/torch/hub/checkpoints/gcresnext26ts_256-e414378b.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:217.26, marginal_mean_neg:177.71\n",
      "joint fit: mean_pos 216.92, r2_pos 0.85\n",
      "joint fit: mean_neg 178.36, r2_neg 0.81\n",
      "\n",
      "processing: legacy_seresnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/se_resnet152-d17c99b7.pth\" to /root/.cache/torch/hub/checkpoints/se_resnet152-d17c99b7.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:1061.08, marginal_mean_neg:768.71\n",
      "joint fit: mean_pos 1059.76, r2_pos 0.89\n",
      "joint fit: mean_neg 773.45, r2_neg 0.86\n",
      "\n",
      "processing: dpn107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-dpn-pretrained/releases/download/v0.1/dpn107_extra-1ac7121e2.pth\" to /root/.cache/torch/hub/checkpoints/dpn107_extra-1ac7121e2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classifier.weight', 'classifier.bias'] (1000, 2688, 1, 1)\n",
      "unable to extract fc layer\n",
      "unable to extract weights\n",
      "\n",
      "processing: dla46x_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://dl.yf.io/dla/models/imagenet/dla46x_c-d761bae7.pth\" to /root/.cache/torch/hub/checkpoints/dla46x_c-d761bae7.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc.weight', 'fc.bias'] (1000, 256, 1, 1)\n",
      "unable to extract fc layer\n",
      "unable to extract weights\n",
      "\n",
      "processing: tf_efficientnet_lite0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite0-0aa007d2.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_lite0-0aa007d2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:185.57, marginal_mean_neg:158.30\n",
      "joint fit: mean_pos 185.24, r2_pos 0.84\n",
      "joint fit: mean_neg 158.84, r2_neg 0.81\n",
      "\n",
      "processing: gernet_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-ger-weights/gernet_s-756b4751.pth\" to /root/.cache/torch/hub/checkpoints/gernet_s-756b4751.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:314.21, marginal_mean_neg:260.61\n",
      "joint fit: mean_pos 315.98, r2_pos 0.86\n",
      "joint fit: mean_neg 260.85, r2_neg 0.84\n",
      "\n",
      "processing: jx_nest_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_base-8bc41011.pth\" to /root/.cache/torch/hub/checkpoints/jx_nest_base-8bc41011.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:120.69, marginal_mean_neg:122.29\n",
      "joint fit: mean_pos 120.79, r2_pos 0.81\n",
      "joint fit: mean_neg 122.53, r2_neg 0.81\n",
      "\n",
      "processing: hardcorenas_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_D_Green_50ms_77.4_23e3cdde.pth\" to /root/.cache/torch/hub/checkpoints/HardCoreNAS_D_Green_50ms_77.4_23e3cdde.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:140.34, marginal_mean_neg:134.81\n",
      "joint fit: mean_pos 140.62, r2_pos 0.83\n",
      "joint fit: mean_neg 135.11, r2_neg 0.82\n",
      "\n",
      "processing: gluon_seresnext101_64x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_seresnext101_64x4d-f9926f93.pth\" to /root/.cache/torch/hub/checkpoints/gluon_seresnext101_64x4d-f9926f93.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:1670.11, marginal_mean_neg:1150.41\n",
      "joint fit: mean_pos 1668.65, r2_pos 0.89\n",
      "joint fit: mean_neg 1169.87, r2_neg 0.86\n",
      "\n",
      "processing: gluon_senet154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_senet154-70a1a3c0.pth\" to /root/.cache/torch/hub/checkpoints/gluon_senet154-70a1a3c0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:880.54, marginal_mean_neg:508.44\n",
      "joint fit: mean_pos 842.25, r2_pos 0.88\n",
      "joint fit: mean_neg 519.94, r2_neg 0.81\n",
      "\n",
      "processing: mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth\" to /root/.cache/torch/hub/checkpoints/mobilenetv3_large_100_ra-f55367f5.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:162.29, marginal_mean_neg:156.33\n",
      "joint fit: mean_pos 162.38, r2_pos 0.82\n",
      "joint fit: mean_neg 156.96, r2_neg 0.82\n",
      "\n",
      "processing: xcit_tiny_12_p16_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/xcit/xcit_tiny_12_p16_224.pth\" to /root/.cache/torch/hub/checkpoints/xcit_tiny_12_p16_224.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:217.00, marginal_mean_neg:216.53\n",
      "joint fit: mean_pos 216.92, r2_pos 0.81\n",
      "joint fit: mean_neg 216.88, r2_neg 0.81\n",
      "\n",
      "processing: gluon_resnet50_v1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-pretrained-gluonresnet/releases/download/v0.1/gluon_resnet50_v1s-1762acc0.pth\" to /root/.cache/torch/hub/checkpoints/gluon_resnet50_v1s-1762acc0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:879.64, marginal_mean_neg:463.20\n",
      "joint fit: mean_pos 871.76, r2_pos 0.90\n",
      "joint fit: mean_neg 464.59, r2_neg 0.80\n",
      "\n",
      "processing: convnext_tiny_hnf\n",
      "marginal_mean_pos:541.60, marginal_mean_neg:537.27\n",
      "joint fit: mean_pos 541.45, r2_pos 0.83\n",
      "joint fit: mean_neg 536.94, r2_neg 0.83\n",
      "\n",
      "processing: resnet26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet26-9aa10e23.pth\" to /root/.cache/torch/hub/checkpoints/resnet26-9aa10e23.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:743.78, marginal_mean_neg:601.14\n",
      "joint fit: mean_pos 748.15, r2_pos 0.88\n",
      "joint fit: mean_neg 601.56, r2_neg 0.85\n",
      "\n",
      "processing: tf_efficientnet_b7_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ns-1dbc32de.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ns-1dbc32de.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:120.26, marginal_mean_neg:126.52\n",
      "joint fit: mean_pos 120.05, r2_pos 0.70\n",
      "joint fit: mean_neg 126.90, r2_neg 0.72\n",
      "\n",
      "processing: tf_efficientnetv2_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_b1-be6e41b0.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnetv2_b1-be6e41b0.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:184.74, marginal_mean_neg:156.53\n",
      "joint fit: mean_pos 183.57, r2_pos 0.84\n",
      "joint fit: mean_neg 157.51, r2_neg 0.81\n",
      "\n",
      "processing: tf_efficientnet_b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b6_aa-80ba17e4.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b6_aa-80ba17e4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:191.33, marginal_mean_neg:171.96\n",
      "joint fit: mean_pos 190.75, r2_pos 0.80\n",
      "joint fit: mean_neg 172.81, r2_neg 0.78\n",
      "\n",
      "processing: vit_small_patch32_224\n",
      "marginal_mean_pos:370.34, marginal_mean_neg:375.24\n",
      "joint fit: mean_pos 371.35, r2_pos 0.83\n",
      "joint fit: mean_neg 376.69, r2_neg 0.83\n",
      "\n",
      "processing: spnasnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/spnasnet_100-048bc3f4.pth\" to /root/.cache/torch/hub/checkpoints/spnasnet_100-048bc3f4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:315.89, marginal_mean_neg:265.84\n",
      "joint fit: mean_pos 317.22, r2_pos 0.86\n",
      "joint fit: mean_neg 267.11, r2_neg 0.83\n",
      "\n",
      "processing: volo_d5_224\n",
      "Unknown model (volo_d5_224)\n",
      "\n",
      "processing: seresnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext50_32x4d_racm-a304a460.pth\" to /root/.cache/torch/hub/checkpoints/seresnext50_32x4d_racm-a304a460.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:338.28, marginal_mean_neg:224.15\n",
      "joint fit: mean_pos 333.70, r2_pos 0.89\n",
      "joint fit: mean_neg 225.16, r2_neg 0.83\n",
      "\n",
      "processing: convnext_large_in22ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_large_22k_1k_224.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:437.50, marginal_mean_neg:442.05\n",
      "joint fit: mean_pos 438.85, r2_pos 0.80\n",
      "joint fit: mean_neg 443.51, r2_neg 0.80\n",
      "\n",
      "processing: densenet169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:2564693.06, marginal_mean_neg:1361543.22\n",
      "joint fit: mean_pos 2534249.59, r2_pos 0.97\n",
      "joint fit: mean_neg 1367003.07, r2_neg 0.95\n",
      "\n",
      "processing: tv_resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:272.32, marginal_mean_neg:173.07\n",
      "joint fit: mean_pos 271.41, r2_pos 0.89\n",
      "joint fit: mean_neg 172.97, r2_neg 0.80\n",
      "\n",
      "processing: eca_nfnet_l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecanfnet_l2_ra3-da781a61.pth\" to /root/.cache/torch/hub/checkpoints/ecanfnet_l2_ra3-da781a61.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:214.29, marginal_mean_neg:184.44\n",
      "joint fit: mean_pos 213.88, r2_pos 0.83\n",
      "joint fit: mean_neg 185.20, r2_neg 0.79\n",
      "\n",
      "processing: haloregnetz_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/haloregnetz_c_raa_256-c8ad7616.pth\" to /root/.cache/torch/hub/checkpoints/haloregnetz_c_raa_256-c8ad7616.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:370.26, marginal_mean_neg:288.11\n",
      "joint fit: mean_pos 370.83, r2_pos 0.86\n",
      "joint fit: mean_neg 287.37, r2_neg 0.85\n",
      "\n",
      "processing: eca_halonext26ts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-attn-weights/eca_halonext26ts_c_256-06906299.pth\" to /root/.cache/torch/hub/checkpoints/eca_halonext26ts_c_256-06906299.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:322.26, marginal_mean_neg:266.88\n",
      "joint fit: mean_pos 321.42, r2_pos 0.86\n",
      "joint fit: mean_neg 267.44, r2_neg 0.83\n",
      "\n",
      "processing: xcit_nano_12_p16_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/xcit/xcit_nano_12_p16_224.pth\" to /root/.cache/torch/hub/checkpoints/xcit_nano_12_p16_224.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:212.22, marginal_mean_neg:211.51\n",
      "joint fit: mean_pos 212.60, r2_pos 0.81\n",
      "joint fit: mean_neg 211.48, r2_neg 0.81\n",
      "\n",
      "processing: volo_d2_224\n",
      "Unknown model (volo_d2_224)\n",
      "\n",
      "processing: resmlp_12_distilled_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/resmlp_12_dist.pth\" to /root/.cache/torch/hub/checkpoints/resmlp_12_dist.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:203.81, marginal_mean_neg:206.77\n",
      "joint fit: mean_pos 203.84, r2_pos 0.82\n",
      "joint fit: mean_neg 206.75, r2_neg 0.82\n",
      "\n",
      "processing: hrnet_w18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-hrnet/hrnetv2_w18-8cb57bb9.pth\" to /root/.cache/torch/hub/checkpoints/hrnetv2_w18-8cb57bb9.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:526.82, marginal_mean_neg:314.83\n",
      "joint fit: mean_pos 524.45, r2_pos 0.89\n",
      "joint fit: mean_neg 315.48, r2_neg 0.80\n",
      "\n",
      "processing: resnetblur50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnetblur50-84f4748f.pth\" to /root/.cache/torch/hub/checkpoints/resnetblur50-84f4748f.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:994.04, marginal_mean_neg:789.60\n",
      "joint fit: mean_pos 997.74, r2_pos 0.88\n",
      "joint fit: mean_neg 795.49, r2_neg 0.85\n",
      "\n",
      "processing: resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_a1_0-14fe96d1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:94.12, marginal_mean_neg:39.65\n",
      "joint fit: mean_pos 93.93, r2_pos 0.87\n",
      "joint fit: mean_neg 39.67, r2_neg 0.82\n",
      "\n",
      "processing: dla60x_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://dl.yf.io/dla/models/imagenet/dla60x_c-b870c45c.pth\" to /root/.cache/torch/hub/checkpoints/dla60x_c-b870c45c.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fc.weight', 'fc.bias'] (1000, 256, 1, 1)\n",
      "unable to extract fc layer\n",
      "unable to extract weights\n",
      "\n",
      "processing: resnet51q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet51q_ra2-d47dcc76.pth\" to /root/.cache/torch/hub/checkpoints/resnet51q_ra2-d47dcc76.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:208.97, marginal_mean_neg:165.74\n",
      "joint fit: mean_pos 208.11, r2_pos 0.86\n",
      "joint fit: mean_neg 166.71, r2_neg 0.81\n",
      "\n",
      "processing: coat_lite_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-coat-weights/coat_lite_small-fea1d5a1.pth\" to /root/.cache/torch/hub/checkpoints/coat_lite_small-fea1d5a1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:167.48, marginal_mean_neg:166.65\n",
      "joint fit: mean_pos 167.70, r2_pos 0.81\n",
      "joint fit: mean_neg 166.87, r2_neg 0.81\n",
      "\n",
      "processing: mixnet_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_m-4647fc68.pth\" to /root/.cache/torch/hub/checkpoints/mixnet_m-4647fc68.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal_mean_pos:217.96, marginal_mean_neg:179.54\n",
      "joint fit: mean_pos 216.34, r2_pos 0.84\n",
      "joint fit: mean_neg 180.98, r2_neg 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_stats_df = setup_imagenet_classes()\n",
    "os.makedirs('./exp_fit_data/', exist_ok=True)\n",
    "model_names = np.random.choice(model_names, 75)\n",
    "for model_name in model_names:\n",
    "    print(\"\\nprocessing:\", model_name)\n",
    "    try:\n",
    "        fc_w, fc_b = setup_weights(model_name)\n",
    "        if fc_w is None:\n",
    "            print('unable to extract weights')\n",
    "            continue\n",
    "        cls_stats_df = fit_exp(cls_stats_df, model_name, fc_w)\n",
    "        cls_stats_df.to_csv(f\"./exp_fit_data/{model_name}.csv\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue    \n",
    "    # clear the weights otherwise kernel will run out of memory\n",
    "    for f in glob(f\"{weight_dir}/{model_name}*.pth\"):\n",
    "        os.remove(f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fcc39",
   "metadata": {
    "papermill": {
     "duration": 0.097828,
     "end_time": "2022-05-21T11:57:17.118538",
     "exception": false,
     "start_time": "2022-05-21T11:57:17.020710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Zip the generated results and clean directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca43f81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T11:57:17.437953Z",
     "iopub.status.busy": "2022-05-21T11:57:17.437653Z",
     "iopub.status.idle": "2022-05-21T11:58:12.285550Z",
     "shell.execute_reply": "2022-05-21T11:58:12.284118Z"
    },
    "papermill": {
     "duration": 54.951846,
     "end_time": "2022-05-21T11:58:12.289206",
     "exception": false,
     "start_time": "2022-05-21T11:57:17.337360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -rq out.zip ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76409aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T11:58:12.516145Z",
     "iopub.status.busy": "2022-05-21T11:58:12.515743Z",
     "iopub.status.idle": "2022-05-21T11:58:14.562968Z",
     "shell.execute_reply": "2022-05-21T11:58:14.562257Z"
    },
    "papermill": {
     "duration": 2.164816,
     "end_time": "2022-05-21T11:58:14.565265",
     "exception": false,
     "start_time": "2022-05-21T11:58:12.400449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "all_dir = glob(\"./*/\")\n",
    "for dir in all_dir:\n",
    "    shutil.rmtree(dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9628.772998,
   "end_time": "2022-05-21T11:58:17.486195",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-21T09:17:48.713197",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
